{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Project OOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing\n",
    "\n",
    "#Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Systems\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The main class - ObjectOrientedTitanic\n",
    "Within the main class, there will be 3 other classes instance called in it. The 3 classes in it are to help manage the information, preprocess, and gridsearchcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectOrientedTitanic():\n",
    "\n",
    "    def __init__(self, train, test):\n",
    "        \"\"\"\n",
    "\n",
    "        :param train: train data will be used for modelling\n",
    "        :param test:  test data will be used for model evaluation\n",
    "        \"\"\"\n",
    "        print(\"ObjectOrientedTitanic object created\")\n",
    "        #properties\n",
    "        self.testPassengerID=test['PassengerId']\n",
    "        self.number_of_train=train.shape[0]\n",
    "\n",
    "        self.y_train=train['Survived']\n",
    "        self.train=train.drop('Survived', axis=1)\n",
    "        self.test=test\n",
    "\n",
    "        #concat train and test data\n",
    "        self.all_data=self._get_all_data()\n",
    "\n",
    "        #Create instance of objects\n",
    "        self._info=Information()\n",
    "        self.preprocessStrategy = PreprocessStrategy()\n",
    "        self.gridSearchHelper = GridSearchHelper()\n",
    "        \n",
    "        \n",
    "    def _get_all_data(self):\n",
    "        return pd.concat([self.train, self.test])\n",
    "\n",
    "    def information(self):\n",
    "        \"\"\"\n",
    "        using _info object gives summary about dataset\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self._info.info(self.all_data)\n",
    "\n",
    "\n",
    "    def preprocessing(self, strategy_type):\n",
    "        \"\"\"\n",
    "        Process data depend upon strategy type\n",
    "        :param strategy_type: Preprocessing strategy type\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.strategy_type=strategy_type\n",
    "\n",
    "        self.all_data = self.preprocessStrategy.strategy(self._get_all_data(), strategy_type)\n",
    "\n",
    "    def machine_learning(self):\n",
    "        \"\"\"\n",
    "        Get self.X_train, self.X_test and self.y_train\n",
    "        Find best parameters for classifiers registered in gridSearchHelper\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self._get_train_and_test()\n",
    "\n",
    "        self.gridSearchHelper.fit_predict_save(self.X_train,\n",
    "                                          self.X_test,\n",
    "                                          self.y_train,\n",
    "                                          self.testPassengerID,\n",
    "                                          self.strategy_type)\n",
    "\n",
    "    def _get_train_and_test(self):\n",
    "        \"\"\"\n",
    "        Split data into train and test datasets\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.X_train=self.all_data[:self.number_of_train]\n",
    "        self.X_test=self.all_data[self.number_of_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Secondary Class - Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Information():\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        This class give some brief information about the datasets.\n",
    "        Information introduced in R language style\n",
    "        \"\"\"\n",
    "        print(\"Information object created\")\n",
    "\n",
    "    def _get_missing_values(self,data):\n",
    "        \"\"\"\n",
    "        Find missing values of given datad\n",
    "        :param data: checked its missing value\n",
    "        :return: Pandas Series object\n",
    "        \"\"\"\n",
    "        #Getting sum of missing values for each feature\n",
    "        missing_values = data.isnull().sum()\n",
    "        #Feature missing values are sorted from few to many\n",
    "        missing_values.sort_values(ascending=False, inplace=True)\n",
    "        \n",
    "        #Returning missing values\n",
    "        return missing_values\n",
    "\n",
    "    def info(self,data):\n",
    "        \"\"\"\n",
    "        print feature name, data type, number of missing values and ten samples of \n",
    "        each feature\n",
    "        :param data: dataset information will be gathered from\n",
    "        :return: no return value\n",
    "        \"\"\"\n",
    "        feature_dtypes=data.dtypes\n",
    "        self.missing_values=self._get_missing_values(data)\n",
    "\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        print(\"{:16} {:16} {:25} {:16}\".format(\"Feature Name\".upper(),\n",
    "                                            \"Data Format\".upper(),\n",
    "                                            \"# of Missing Values\".upper(),\n",
    "                                            \"Samples\".upper()))\n",
    "        for feature_name, dtype, missing_value in zip(self.missing_values.index.values,\n",
    "                                                      feature_dtypes[self.missing_values.index.values],\n",
    "                                                      self.missing_values.values):\n",
    "            print(\"{:18} {:19} {:19} \".format(feature_name, str(dtype), str(missing_value)), end=\"\")\n",
    "            for v in data[feature_name].values[:10]:\n",
    "                print(v, end=\",\")\n",
    "            print()\n",
    "\n",
    "        print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Secondary Class - Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocess():\n",
    "\n",
    "    def __init__(self):\n",
    "        print(\"Preprocess object created\")\n",
    "\n",
    "    def fillna(self, data, fill_strategies):\n",
    "        for column, strategy in fill_strategies.items():\n",
    "            if strategy == 'None':\n",
    "                data[column] = data[column].fillna('None')\n",
    "            elif strategy == 'Zero':\n",
    "                data[column] = data[column].fillna(0)\n",
    "            elif strategy == 'Mode':\n",
    "                data[column] = data[column].fillna(data[column].mode()[0])\n",
    "            elif strategy == 'Mean':\n",
    "                data[column] = data[column].fillna(data[column].mean())\n",
    "            elif strategy == 'Median':\n",
    "                data[column] = data[column].fillna(data[column].median())\n",
    "            else:\n",
    "                print(\"{}: There is no such thing as preprocess strategy\".format(strategy))\n",
    "\n",
    "        return data\n",
    "\n",
    "    def drop(self, data, drop_strategies):\n",
    "        for column, strategy in drop_strategies.items():\n",
    "            data=data.drop(labels=[column], axis=strategy)\n",
    "\n",
    "        return data\n",
    "\n",
    "    def feature_engineering(self, data, engineering_strategies=1):\n",
    "        if engineering_strategies==1:\n",
    "            return self._feature_engineering1(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "    def _feature_engineering1(self,data):\n",
    "\n",
    "        data=self._base_feature_engineering(data)\n",
    "\n",
    "\n",
    "        data['FareBin'] = pd.qcut(data['Fare'], 4)\n",
    "\n",
    "        data['AgeBin'] = pd.cut(data['Age'].astype(int), 5)\n",
    "\n",
    "        drop_strategy = {'Age': 1,  # 1 indicate axis 1(column)\n",
    "                         'Name': 1,\n",
    "                         'Fare': 1}\n",
    "        data = self.drop(data, drop_strategy)\n",
    "\n",
    "        return data\n",
    "\n",
    "    def _base_feature_engineering(self,data):\n",
    "        data['FamilySize'] = data['SibSp'] + data['Parch'] + 1\n",
    "\n",
    "        data['IsAlone'] = 1\n",
    "        data.loc[(data['FamilySize'] > 1), 'IsAlone'] = 0\n",
    "\n",
    "        data['Title'] = data['Name'].str.split(\", \", expand=True)[1].str.split('.', expand=True)[0]\n",
    "        min_lengtht = 10\n",
    "        title_names = (data['Title'].value_counts() < min_lengtht)\n",
    "        data['Title'] = data['Title'].apply(lambda x: 'Misc' if title_names.loc[x] == True else x)\n",
    "\n",
    "        return data\n",
    "\n",
    "    def _label_encoder(self,data):\n",
    "        labelEncoder=LabelEncoder()\n",
    "        for column in data.columns.values:\n",
    "            if 'int64'==data[column].dtype or 'float64'==data[column].dtype or 'int64'==data[column].dtype:\n",
    "                continue\n",
    "            labelEncoder.fit(data[column])\n",
    "            data[column]=labelEncoder.transform(data[column])\n",
    "        return data\n",
    "\n",
    "    def _get_dummies(self, data, prefered_columns=None):\n",
    "\n",
    "        if prefered_columns is None:\n",
    "            columns=data.columns.values\n",
    "            non_dummies=None\n",
    "        else:\n",
    "            non_dummies=[col for col in data.columns.values if col not in prefered_columns ]\n",
    "\n",
    "            columns=prefered_columns\n",
    "\n",
    "\n",
    "        dummies_data=[pd.get_dummies(data[col],prefix=col) for col in columns]\n",
    "\n",
    "        if non_dummies is not None:\n",
    "            for non_dummy in non_dummies:\n",
    "                dummies_data.append(data[non_dummy])\n",
    "\n",
    "        return pd.concat(dummies_data, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessStrategy():\n",
    "    \"\"\"\n",
    "    Preprocess strategies defined and exected in this class\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.data=None\n",
    "        self._preprocessor=Preprocess()\n",
    "\n",
    "    def strategy(self, data, strategy_type=\"strategy1\"):\n",
    "        self.data=data\n",
    "        if strategy_type=='strategy1':\n",
    "            self._strategy1()\n",
    "        elif strategy_type=='strategy2':\n",
    "            self._strategy2()\n",
    "\n",
    "        return self.data\n",
    "\n",
    "    def _base_strategy(self):\n",
    "        drop_strategy = {'PassengerId': 1,  # 1 indicate axis 1(column)\n",
    "                         'Cabin': 1,\n",
    "                         'Ticket': 1}\n",
    "        self.data = self._preprocessor.drop(self.data, drop_strategy)\n",
    "\n",
    "        fill_strategy = {'Age': 'Median',\n",
    "                         'Fare': 'Median',\n",
    "                         'Embarked': 'Mode'}\n",
    "        self.data = self._preprocessor.fillna(self.data, fill_strategy)\n",
    "\n",
    "        self.data = self._preprocessor.feature_engineering(self.data, 1)\n",
    "\n",
    "\n",
    "        self.data = self._preprocessor._label_encoder(self.data)\n",
    "\n",
    "    def _strategy1(self):\n",
    "        self._base_strategy()\n",
    "\n",
    "        self.data=self._preprocessor._get_dummies(self.data,\n",
    "                                        prefered_columns=['Pclass', 'Sex', 'Parch', 'Embarked', 'Title', 'IsAlone'])\n",
    "\n",
    "    def _strategy2(self):\n",
    "        self._base_strategy()\n",
    "\n",
    "        self.data=self._preprocessor._get_dummies(self.data,\n",
    "                                        prefered_columns=None)#None mean that all feature will be dummied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Secondary Class - GridSearchHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridSearchHelper():\n",
    "    def __init__(self):\n",
    "        print(\"GridSearchHelper Created\")\n",
    "\n",
    "        self.gridSearchCV=None\n",
    "        self.clf_and_params=list()\n",
    "\n",
    "        self._initialize_clf_and_params()\n",
    "\n",
    "    def _initialize_clf_and_params(self):\n",
    "\n",
    "        clf= KNeighborsClassifier()\n",
    "        params={'n_neighbors':[5,7,9,11,13,15],\n",
    "          'leaf_size':[1,2,3,5],\n",
    "          'weights':['uniform', 'distance']\n",
    "          }\n",
    "        self.clf_and_params.append((clf, params))\n",
    "\n",
    "        clf=LogisticRegression()\n",
    "        params={'penalty':['l1', 'l2'],\n",
    "                'C':np.logspace(0, 4, 10)\n",
    "                }\n",
    "        self.clf_and_params.append((clf, params))\n",
    "\n",
    "        clf = SVC()\n",
    "        params = [ {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "                   {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']}]\n",
    "        self.clf_and_params.append((clf, params))\n",
    "\n",
    "        clf=DecisionTreeClassifier()\n",
    "        params={'max_features': ['auto', 'sqrt', 'log2'],\n",
    "          'min_samples_split': [2,3,4,5,6,7,8,9,10,11,12,13,14,15],\n",
    "          'min_samples_leaf':[1],\n",
    "          'random_state':[123]}\n",
    "        #Because of depricating warning for Decision Tree which is not appended.\n",
    "        #But it give high competion accuracy score. You can append when you run the kernel\n",
    "        #self.clf_and_params.append((clf,params))\n",
    "\n",
    "        clf = RandomForestClassifier()\n",
    "        params = {'n_estimators': [4, 6, 9],\n",
    "              'max_features': ['log2', 'sqrt','auto'],\n",
    "              'criterion': ['entropy', 'gini'],\n",
    "              'max_depth': [2, 3, 5, 10],\n",
    "              'min_samples_split': [2, 3, 5],\n",
    "              'min_samples_leaf': [1,5,8]\n",
    "             }\n",
    "        #Because of depricating warning for RandomForestClassifier which is not appended.\n",
    "        #But it give high competion accuracy score. You can append when you run the kernel\n",
    "        #self.clf_and_params.append((clf, params))\n",
    "\n",
    "    def fit_predict_save(self, X_train, X_test, y_train, submission_id, strategy_type):\n",
    "        self.X_train=X_train\n",
    "        self.X_test=X_test\n",
    "        self.y_train=y_train\n",
    "        self.submission_id=submission_id\n",
    "        self.strategy_type=strategy_type\n",
    "\n",
    "        clf_and_params = self.get_clf_and_params()\n",
    "        models=[]\n",
    "        for clf, params in clf_and_params:\n",
    "            self.current_clf_name = clf.__class__.__name__\n",
    "            grid_search_clf = GridSearchCV(clf, params, cv=5)\n",
    "            grid_search_clf.fit(self.X_train, self.y_train)\n",
    "            self.Y_pred = grid_search_clf.predict(self.X_test)\n",
    "            clf_train_acc = round(grid_search_clf.score(self.X_train, self.y_train) * 100, 2)\n",
    "            print(self.current_clf_name, \" train accuracy:\", clf_train_acc)\n",
    "            \n",
    "            # for ensemble\n",
    "            models.append(clf)\n",
    "\n",
    "            self.save_result()\n",
    "            print()\n",
    "        \n",
    "        \"\"\"\n",
    "        voting_clf=VotingClassifier(models)\n",
    "        voting_clf.fit(self.X_train, self.y_train)\n",
    "        self.Y_pred=voting_clf.predict(self.X_test)\n",
    "        self.current_clf_name = clf.__class__.__name__\n",
    "        clf_train_acc = round(voting_clf.score(self.X_train, self.y_train) * 100, 2)\n",
    "        print(self.current_clf_name, \" train accuracy:\", clf_train_acc)\n",
    "        self.save_result()\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "    def save_result(self):\n",
    "        Submission = pd.DataFrame({'PassengerId': self.submission_id,\n",
    "                                           'Survived': self.Y_pred})\n",
    "        file_name=\"{}_{}.csv\".format(self.strategy_type,self.current_clf_name.lower())\n",
    "        Submission.to_csv(file_name, index=False)\n",
    "\n",
    "        print(\"Submission saved file name: \",file_name)\n",
    "\n",
    "    def get_clf_and_params(self):\n",
    "\n",
    "        return self.clf_and_params\n",
    "\n",
    "    def add(self,clf, params):\n",
    "        self.clf_and_params.append((clf, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the main class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ObjectOrientedTitanic object created\n",
      "Information object created\n",
      "Preprocess object created\n",
      "GridSearchHelper Created\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"/home/jasonchandatascience/advanced-python/datasets/titanic/train.csv\")\n",
    "test = pd.read_csv(\"/home/jasonchandatascience/advanced-python/datasets/titanic/test.csv\")\n",
    "\n",
    "objectOrientedTitanic=ObjectOrientedTitanic(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "FEATURE NAME     DATA FORMAT      # OF MISSING VALUES       SAMPLES         \n",
      "Cabin              object              1014                nan,C85,nan,C123,nan,nan,E46,nan,nan,nan,\n",
      "Age                float64             263                 22.0,38.0,26.0,35.0,35.0,nan,54.0,2.0,27.0,14.0,\n",
      "Embarked           object              2                   S,C,S,S,S,Q,S,S,S,C,\n",
      "Fare               float64             1                   7.25,71.2833,7.925,53.1,8.05,8.4583,51.8625,21.075,11.1333,30.0708,\n",
      "Ticket             object              0                   A/5 21171,PC 17599,STON/O2. 3101282,113803,373450,330877,17463,349909,347742,237736,\n",
      "Parch              int64               0                   0,0,0,0,0,0,0,1,2,0,\n",
      "SibSp              int64               0                   1,1,0,1,0,0,0,3,0,1,\n",
      "Sex                object              0                   male,female,female,female,male,male,male,male,female,female,\n",
      "Name               object              0                   Braund, Mr. Owen Harris,Cumings, Mrs. John Bradley (Florence Briggs Thayer),Heikkinen, Miss. Laina,Futrelle, Mrs. Jacques Heath (Lily May Peel),Allen, Mr. William Henry,Moran, Mr. James,McCarthy, Mr. Timothy J,Palsson, Master. Gosta Leonard,Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg),Nasser, Mrs. Nicholas (Adele Achem),\n",
      "Pclass             int64               0                   3,1,3,1,3,3,1,3,3,2,\n",
      "PassengerId        int64               0                   1,2,3,4,5,6,7,8,9,10,\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "objectOrientedTitanic.information()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "objectOrientedTitanic.preprocessing(strategy_type='strategy1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "FEATURE NAME     DATA FORMAT      # OF MISSING VALUES       SAMPLES         \n",
      "AgeBin             int64               0                   1,2,1,2,2,1,3,0,1,0,\n",
      "Parch_9            uint8               0                   0,0,0,0,0,0,0,0,0,0,\n",
      "Pclass_2           uint8               0                   0,0,0,0,0,0,0,0,0,1,\n",
      "Pclass_3           uint8               0                   1,0,1,0,1,1,0,1,1,0,\n",
      "Sex_0              uint8               0                   0,1,1,1,0,0,0,0,1,1,\n",
      "Sex_1              uint8               0                   1,0,0,0,1,1,1,1,0,0,\n",
      "Parch_0            uint8               0                   1,1,1,1,1,1,1,0,0,1,\n",
      "Parch_1            uint8               0                   0,0,0,0,0,0,0,1,0,0,\n",
      "Parch_2            uint8               0                   0,0,0,0,0,0,0,0,1,0,\n",
      "Parch_3            uint8               0                   0,0,0,0,0,0,0,0,0,0,\n",
      "Parch_4            uint8               0                   0,0,0,0,0,0,0,0,0,0,\n",
      "Parch_5            uint8               0                   0,0,0,0,0,0,0,0,0,0,\n",
      "Parch_6            uint8               0                   0,0,0,0,0,0,0,0,0,0,\n",
      "Embarked_0         uint8               0                   0,1,0,0,0,0,0,0,0,1,\n",
      "FareBin            int64               0                   0,3,1,3,1,1,3,2,1,2,\n",
      "Embarked_1         uint8               0                   0,0,0,0,0,1,0,0,0,0,\n",
      "Embarked_2         uint8               0                   1,0,1,1,1,0,1,1,1,0,\n",
      "Title_0            uint8               0                   0,0,0,0,0,0,0,1,0,0,\n",
      "Title_1            uint8               0                   0,0,0,0,0,0,0,0,0,0,\n",
      "Title_2            uint8               0                   0,0,1,0,0,0,0,0,0,0,\n",
      "Title_3            uint8               0                   1,0,0,0,1,1,1,0,0,0,\n",
      "Title_4            uint8               0                   0,1,0,1,0,0,0,0,1,1,\n",
      "IsAlone_0          uint8               0                   1,1,0,1,0,0,0,1,1,1,\n",
      "IsAlone_1          uint8               0                   0,0,1,0,1,1,1,0,0,0,\n",
      "SibSp              int64               0                   1,1,0,1,0,0,0,3,0,1,\n",
      "FamilySize         int64               0                   2,2,1,2,1,1,1,5,3,2,\n",
      "Pclass_1           uint8               0                   0,1,0,1,0,0,1,0,0,0,\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "objectOrientedTitanic.information()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier  train accuracy: 83.84\n",
      "Submission saved file name:  strategy1_kneighborsclassifier.csv\n",
      "\n",
      "LogisticRegression  train accuracy: 82.94\n",
      "Submission saved file name:  strategy1_logisticregression.csv\n",
      "\n",
      "SVC  train accuracy: 83.16\n",
      "Submission saved file name:  strategy1_svc.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "objectOrientedTitanic.machine_learning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ObjectOrientedTitanic object created\n",
      "Information object created\n",
      "Preprocess object created\n",
      "GridSearchHelper Created\n"
     ]
    }
   ],
   "source": [
    "objectOrientedTitanic2=ObjectOrientedTitanic(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "FEATURE NAME     DATA FORMAT      # OF MISSING VALUES       SAMPLES         \n",
      "Cabin              object              1014                nan,C85,nan,C123,nan,nan,E46,nan,nan,nan,\n",
      "Age                float64             263                 22.0,38.0,26.0,35.0,35.0,nan,54.0,2.0,27.0,14.0,\n",
      "Embarked           object              2                   S,C,S,S,S,Q,S,S,S,C,\n",
      "Fare               float64             1                   7.25,71.2833,7.925,53.1,8.05,8.4583,51.8625,21.075,11.1333,30.0708,\n",
      "Ticket             object              0                   A/5 21171,PC 17599,STON/O2. 3101282,113803,373450,330877,17463,349909,347742,237736,\n",
      "Parch              int64               0                   0,0,0,0,0,0,0,1,2,0,\n",
      "SibSp              int64               0                   1,1,0,1,0,0,0,3,0,1,\n",
      "Sex                object              0                   male,female,female,female,male,male,male,male,female,female,\n",
      "Name               object              0                   Braund, Mr. Owen Harris,Cumings, Mrs. John Bradley (Florence Briggs Thayer),Heikkinen, Miss. Laina,Futrelle, Mrs. Jacques Heath (Lily May Peel),Allen, Mr. William Henry,Moran, Mr. James,McCarthy, Mr. Timothy J,Palsson, Master. Gosta Leonard,Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg),Nasser, Mrs. Nicholas (Adele Achem),\n",
      "Pclass             int64               0                   3,1,3,1,3,3,1,3,3,2,\n",
      "PassengerId        int64               0                   1,2,3,4,5,6,7,8,9,10,\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "objectOrientedTitanic2.information()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "objectOrientedTitanic2.preprocessing(strategy_type='strategy2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier  train accuracy: 84.96\n",
      "Submission saved file name:  strategy2_kneighborsclassifier.csv\n",
      "\n",
      "LogisticRegression  train accuracy: 82.6\n",
      "Submission saved file name:  strategy2_logisticregression.csv\n",
      "\n",
      "SVC  train accuracy: 82.94\n",
      "Submission saved file name:  strategy2_svc.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "objectOrientedTitanic2.machine_learning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "FEATURE NAME     DATA FORMAT      # OF MISSING VALUES       SAMPLES         \n",
      "AgeBin_4           uint8               0                   0,0,0,0,0,0,0,0,0,0,\n",
      "AgeBin_3           uint8               0                   0,0,0,0,0,0,1,0,0,0,\n",
      "Embarked_1         uint8               0                   0,0,0,0,0,1,0,0,0,0,\n",
      "Embarked_0         uint8               0                   0,1,0,0,0,0,0,0,0,1,\n",
      "Parch_9            uint8               0                   0,0,0,0,0,0,0,0,0,0,\n",
      "Parch_6            uint8               0                   0,0,0,0,0,0,0,0,0,0,\n",
      "Parch_5            uint8               0                   0,0,0,0,0,0,0,0,0,0,\n",
      "Parch_4            uint8               0                   0,0,0,0,0,0,0,0,0,0,\n",
      "Parch_3            uint8               0                   0,0,0,0,0,0,0,0,0,0,\n",
      "Parch_2            uint8               0                   0,0,0,0,0,0,0,0,1,0,\n",
      "Parch_1            uint8               0                   0,0,0,0,0,0,0,1,0,0,\n",
      "Parch_0            uint8               0                   1,1,1,1,1,1,1,0,0,1,\n",
      "SibSp_8            uint8               0                   0,0,0,0,0,0,0,0,0,0,\n",
      "SibSp_5            uint8               0                   0,0,0,0,0,0,0,0,0,0,\n",
      "SibSp_4            uint8               0                   0,0,0,0,0,0,0,0,0,0,\n",
      "SibSp_3            uint8               0                   0,0,0,0,0,0,0,1,0,0,\n",
      "SibSp_2            uint8               0                   0,0,0,0,0,0,0,0,0,0,\n",
      "SibSp_1            uint8               0                   1,1,0,1,0,0,0,0,0,1,\n",
      "SibSp_0            uint8               0                   0,0,1,0,1,1,1,0,1,0,\n",
      "Sex_1              uint8               0                   1,0,0,0,1,1,1,1,0,0,\n",
      "Sex_0              uint8               0                   0,1,1,1,0,0,0,0,1,1,\n",
      "Pclass_3           uint8               0                   1,0,1,0,1,1,0,1,1,0,\n",
      "Pclass_2           uint8               0                   0,0,0,0,0,0,0,0,0,1,\n",
      "Embarked_2         uint8               0                   1,0,1,1,1,0,1,1,1,0,\n",
      "FamilySize_1       uint8               0                   0,0,1,0,1,1,1,0,0,0,\n",
      "FamilySize_2       uint8               0                   1,1,0,1,0,0,0,0,0,1,\n",
      "Title_2            uint8               0                   0,0,1,0,0,0,0,0,0,0,\n",
      "AgeBin_2           uint8               0                   0,1,0,1,1,0,0,0,0,0,\n",
      "AgeBin_1           uint8               0                   1,0,1,0,0,1,0,0,1,0,\n",
      "AgeBin_0           uint8               0                   0,0,0,0,0,0,0,1,0,1,\n",
      "FareBin_3          uint8               0                   0,1,0,1,0,0,1,0,0,0,\n",
      "FareBin_2          uint8               0                   0,0,0,0,0,0,0,1,0,1,\n",
      "FareBin_1          uint8               0                   0,0,1,0,1,1,0,0,1,0,\n",
      "FareBin_0          uint8               0                   1,0,0,0,0,0,0,0,0,0,\n",
      "Title_4            uint8               0                   0,1,0,1,0,0,0,0,1,1,\n",
      "Title_3            uint8               0                   1,0,0,0,1,1,1,0,0,0,\n",
      "Title_1            uint8               0                   0,0,0,0,0,0,0,0,0,0,\n",
      "FamilySize_3       uint8               0                   0,0,0,0,0,0,0,0,1,0,\n",
      "Title_0            uint8               0                   0,0,0,0,0,0,0,1,0,0,\n",
      "IsAlone_1          uint8               0                   0,0,1,0,1,1,1,0,0,0,\n",
      "IsAlone_0          uint8               0                   1,1,0,1,0,0,0,1,1,1,\n",
      "FamilySize_11      uint8               0                   0,0,0,0,0,0,0,0,0,0,\n",
      "FamilySize_8       uint8               0                   0,0,0,0,0,0,0,0,0,0,\n",
      "FamilySize_7       uint8               0                   0,0,0,0,0,0,0,0,0,0,\n",
      "FamilySize_6       uint8               0                   0,0,0,0,0,0,0,0,0,0,\n",
      "FamilySize_5       uint8               0                   0,0,0,0,0,0,0,1,0,0,\n",
      "FamilySize_4       uint8               0                   0,0,0,0,0,0,0,0,0,0,\n",
      "Pclass_1           uint8               0                   0,1,0,1,0,0,1,0,0,0,\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "objectOrientedTitanic2.information()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
